{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from animalai.envs.actions import AAIActions, AAIAction\n",
    "from animalai.envs.raycastparser import RayCastParser\n",
    "from animalai.envs.raycastparser import RayCastObjects\n",
    "from animalai.envs.environment import AnimalAIEnvironment\n",
    "from mlagents_envs.envs.unity_gym_env import UnityToGymWrapper\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import NamedTuple, Dict, Optional, List\n",
    "\n",
    "#Braitenberg vehicle 1) Moves a few steps forward [to avoid clear walls] 2) Moves towards walls 3) Moves a few steps randomly 4)Moves towards target [which will hopefully be in sight and they will not be stuck by a wall]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "aai_seed = random.randint(\n",
    "    0, 10000\n",
    ") # set the seed for the random number generator, and then vary this to make a population of agents\n",
    "\n",
    "NUM_RAYS = 7 # number of rays to use in raycast, see here: https://github.com/Kinds-of-Intelligence-CFI/animal-ai/blob/main/docs/observations.md\n",
    "STEP_LENGTH = 5 # how many steps to take before taking a random action, vary this to make a population of agents\n",
    "NUM_EPISODES = 18 # add number of episodes for testing\n",
    "\n",
    "agent_inference = True\n",
    "\n",
    "agent_name = \"BraitenbergVehicle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_file = r\"/Users/nataszasiwinska/Documents/research_projects/animal-ai-main/configs/combined_short.yml\"\n",
    "env_path = r\"/Users/nataszasiwinska/Documents/research_projects/animal-ai-main/env/AAI3Mac.app\"\n",
    "log_folder_path = r\"/Users/nataszasiwinska/Documents/research_projects/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Braitenberg vehicle design by M. D. Crosby.\n",
    "# Adapted by K. Voudouris where noted.\n",
    "# Futher adapted by N. Siwinska \n",
    "\n",
    "class Braitenberg():\n",
    "    \"\"\"Implements a simple Braitenberg vehicle agent that heads towards food\n",
    "    Can change the number of rays but only responds to GOODGOALs, GOODGOALMULTI and BADGOAL\"\"\"\n",
    "    def __init__(self, no_rays, step_length):\n",
    "        self.no_rays = no_rays\n",
    "        assert(self.no_rays % 2 == 1), \"Only supports odd number of rays (but environment should only allow odd number)\"\n",
    "        \n",
    "        self.step_length = step_length\n",
    "        assert(self.step_length >= 1), \"Only supports step lengths greater than or equal to 1\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Note that BADGOAL includes both red goals AND death zones.\n",
    "        \"\"\"\n",
    "        self.listOfObjects = [RayCastObjects.GOODGOAL, RayCastObjects.GOODGOALMULTI, RayCastObjects.BADGOAL, RayCastObjects.IMMOVABLE]\n",
    "        self.raycast_parser = RayCastParser([RayCastObjects.GOODGOAL, RayCastObjects.GOODGOALMULTI, RayCastObjects.BADGOAL, RayCastObjects.IMMOVABLE], self.no_rays)\n",
    "        self.actions = AAIActions()\n",
    "        self.prev_action = self.actions.NOOP\n",
    "\n",
    "    def prettyPrint(self, obs) -> str:\n",
    "        \"\"\"Prints the parsed observation\"\"\"\n",
    "        return self.raycast_parser.prettyPrint(obs)\n",
    "    \n",
    "    def get_action(self, obs, step_length) -> AAIAction:\n",
    "        \"\"\"Returns the action to take given the current parsed raycast observation\"\"\"\n",
    "        obs = self.raycast_parser.parse(obs)\n",
    "        newAction = self.actions.NOOP\n",
    "        if self.ahead(obs, RayCastObjects.GOODGOAL):\n",
    "            newAction = self.actions.FORWARDS\n",
    "        elif self.left(obs, RayCastObjects.GOODGOAL):\n",
    "            newAction = self.actions.FORWARDSLEFT\n",
    "        elif self.right(obs, RayCastObjects.GOODGOAL):\n",
    "            newAction = self.actions.FORWARDSRIGHT\n",
    "        #elif self.ahead(obs, RayCastObjects.BADGOAL):\n",
    "            #newAction = self.actions.BACKWARDS\n",
    "        #elif self.left(obs, RayCastObjects.BADGOAL):\n",
    "            #newAction = self.actions.BACKWARDSLEFT\n",
    "        #elif self.right(obs, RayCastObjects.BADGOAL):\n",
    "            #newAction = self.actions.BACKWARDSRIGHT\n",
    "        else:\n",
    "            #If the agent is not at or further than the y=1.3 coordinate (as there is no advantage to random movement when there are clear walls on either side), the direction it should take is straight. \n",
    "            if np.array(movement[1] > 1.3) == True: \n",
    "                newAction = self.actions.FORWARDS\n",
    "            #if self.prev_action == self.actions.NOOP or self.prev_action == self.actions.BACKWARDS:\n",
    "            take_steps = random.randint(0, step_length) \n",
    "            if take_steps != 0:\n",
    "                newAction = self.prev_action\n",
    "                rand_action = random.randint(0,15) # pick either random actions (56% chance) or reactions based on sensing immovable objects straight ahead (44% chance) \n",
    "                if  (rand_action == 0):\n",
    "                    newAction = self.actions.NOOP\n",
    "                elif (rand_action == 1):\n",
    "                    newAction = self.actions.FORWARDS\n",
    "                elif (rand_action == 2): \n",
    "                    newAction = self.actions.FORWARDSRIGHT\n",
    "                elif (rand_action == 3):\n",
    "                    newAction = self.actions.RIGHT\n",
    "                elif (rand_action == 4):\n",
    "                    newAction = self.actions.BACKWARDSRIGHT\n",
    "                elif (rand_action == 5):\n",
    "                    newAction = self.actions.BACKWARDS\n",
    "                elif (rand_action == 6):\n",
    "                    newAction = self.actions.BACKWARDSLEFT\n",
    "                elif (rand_action == 7):\n",
    "                    newAction = self.actions.LEFT\n",
    "                elif (rand_action == 8):\n",
    "                    newAction = self.actions.FORWARDSLEFT\n",
    "                elif (rand_action == 9 or 10 or 11 or 12 or 13 or 14 or 15):\n",
    "                    if self.ahead(obs, RayCastObjects.IMMOVABLE):\n",
    "                        #If an object is sensed in front,then perform random actions as per the chances given;\n",
    "                        newAction = self.prev_action\n",
    "                        rand_action_wall = random.randint(0,10) # pick one of 6 actions randomly, with the highest chance being a forward movement (55% forwards left, forwards right or forwards)\n",
    "                        if  (rand_action_wall == 0 ):\n",
    "                            newAction = self.actions.BACKWARDS\n",
    "                        elif (rand_action_wall == 1 or 2):\n",
    "                            newAction = self.actions.FORWARDSRIGHT\n",
    "                        elif (rand_action_wall == 3 or 4): \n",
    "                            newAction = self.actions.FORWARDSLEFT\n",
    "                        elif (rand_action_wall == 5):\n",
    "                            newAction = self.actions.BACKWARDSLEFT\n",
    "                        elif (rand_action_wall == 6): \n",
    "                            newAction = self.actions.BACKWARDSRIGHT\n",
    "                        elif (rand_action_wall == 7):\n",
    "                            newAction = self.actions.LEFT\n",
    "                        elif (rand_action_wall == 8):\n",
    "                            newAction = self.actions.RIGHT\n",
    "                        elif (rand_action_wall == 9 or 10):\n",
    "                            newAction = self.actions.FORWARDS\n",
    "                    elif self.left(obs, RayCastObjects.IMMOVABLE):\n",
    "                        newAction = self.actions.FORWARDSLEFT\n",
    "                    elif self.right(obs, RayCastObjects.IMMOVABLE):\n",
    "                        newAction = self.actions.FORWARDSRIGHT\n",
    "                    elif self.ahead(obs, RayCastObjects.BADGOAL):\n",
    "                        newAction = self.actions.BACKWARDS\n",
    "                    elif self.left(obs, RayCastObjects.BADGOAL):\n",
    "                        newAction = self.actions.BACKWARDSLEFT\n",
    "                    elif self.right(obs, RayCastObjects.BADGOAL):\n",
    "                        newAction = self.actions.BACKWARDSRIGHT\n",
    "            #    newAction = self.prev_action  \n",
    "            #elif self.ahead(obs, RayCastObjects.BADGOAL):\n",
    "                #newAction = self.actions.BACKWARDS\n",
    "            #elif self.left(obs, RayCastObjects.BADGOAL):\n",
    "                #newAction = self.actions.BACKWARDSLEFT\n",
    "            #elif self.right(obs, RayCastObjects.BADGOAL):\n",
    "                #newAction = self.actions.BACKWARDSRIGHT\n",
    "        self.prev_action = newAction\n",
    "        return newAction\n",
    "        \n",
    "\n",
    "\n",
    "    def ahead(self, obs, object):\n",
    "        \"\"\"Returns true if the input object is ahead of the agent\"\"\"\n",
    "        if(obs[self.listOfObjects.index(object)][int((self.no_rays-1)/2)] > 0):\n",
    "            # print(\"found \" + str(object) + \" ahead\")\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def left(self, obs, object):\n",
    "        \"\"\"Returns true if the input object is left of the agent\"\"\"\n",
    "        for i in range(int((self.no_rays-1)/2)):\n",
    "            if(obs[self.listOfObjects.index(object)][i] > 0):\n",
    "                # print(\"found \" + str(object) + \" left\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def right(self, obs, object):\n",
    "        \"\"\"Returns true if the input object is right of the agent\"\"\"\n",
    "        for i in range(int((self.no_rays-1)/2)):\n",
    "            if(obs[self.listOfObjects.index(object)][i+int((self.no_rays-1)/2) + 1] > 0):\n",
    "                # print(\"found \" + str(object) + \" right\")\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "UnityEnvironmentException",
     "evalue": "Environment shut down with return code -9 (SIGKILL).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      1\u001b[0m random\u001b[39m.\u001b[39mseed(aai_seed) \u001b[39m#set seed for random action selection\u001b[39;00m\n\u001b[1;32m      3\u001b[0m port \u001b[39m=\u001b[39m \u001b[39m5005\u001b[39m \u001b[39m+\u001b[39m random\u001b[39m.\u001b[39mrandint(\n\u001b[1;32m      4\u001b[0m     \u001b[39m0\u001b[39m, \u001b[39m1000\u001b[39m\n\u001b[1;32m      5\u001b[0m )  \u001b[39m# use a random port to avoid problems if a previous version exits slowly\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m aai_env \u001b[39m=\u001b[39m AnimalAIEnvironment( \n\u001b[1;32m      8\u001b[0m     inference\u001b[39m=\u001b[39;49magent_inference,\n\u001b[1;32m      9\u001b[0m     seed \u001b[39m=\u001b[39;49m aai_seed,\n\u001b[1;32m     10\u001b[0m     log_folder \u001b[39m=\u001b[39;49m log_folder_path,\n\u001b[1;32m     11\u001b[0m     worker_id\u001b[39m=\u001b[39;49maai_seed,\n\u001b[1;32m     12\u001b[0m     file_name\u001b[39m=\u001b[39;49menv_path,\n\u001b[1;32m     13\u001b[0m     arenas_configurations\u001b[39m=\u001b[39;49mconfiguration_file,\n\u001b[1;32m     14\u001b[0m     base_port\u001b[39m=\u001b[39;49mport,\n\u001b[1;32m     15\u001b[0m     useCamera\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m# uses raycasts instaed\u001b[39;49;00m\n\u001b[1;32m     16\u001b[0m     \u001b[39m#resolution=36,\u001b[39;49;00m\n\u001b[1;32m     17\u001b[0m     useRayCasts\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     18\u001b[0m     raysPerSide \u001b[39m=\u001b[39;49m \u001b[39mint\u001b[39;49m((NUM_RAYS\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\u001b[39m/\u001b[39;49m\u001b[39m2\u001b[39;49m),\n\u001b[1;32m     19\u001b[0m     rayMaxDegrees \u001b[39m=\u001b[39;49m \u001b[39m30\u001b[39;49m\n\u001b[1;32m     20\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[39m#env = UnityToGymWrapper(aai_env, uint8_visual=False, allow_multiple_obs=False, flatten_branched=True)\u001b[39;00m\n\u001b[1;32m     24\u001b[0m obs \u001b[39m=\u001b[39m aai_env\u001b[39m.\u001b[39mreset()\n",
      "File \u001b[0;32m~/Documents/research_projects/animal-ai-main/animalai/animalai/envs/environment.py:87\u001b[0m, in \u001b[0;36mAnimalAIEnvironment.__init__\u001b[0;34m(self, additional_args, log_folder, file_name, worker_id, base_port, seed, play, arenas_configurations, inference, useCamera, resolution, grayscale, useRayCasts, raysPerSide, rayMaxDegrees, decisionPeriod, side_channels, no_graphics, use_YAML)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39m# self.captureFrameRate = captureFrameRate\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m# self.targetFrameRate = targetFrameRate\u001b[39;00m\n\u001b[1;32m     85\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mconfigure_side_channels(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mside_channels)\n\u001b[0;32m---> 87\u001b[0m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(\n\u001b[1;32m     88\u001b[0m     file_name\u001b[39m=\u001b[39;49mfile_name,\n\u001b[1;32m     89\u001b[0m     worker_id\u001b[39m=\u001b[39;49mworker_id,\n\u001b[1;32m     90\u001b[0m     base_port\u001b[39m=\u001b[39;49mbase_port,\n\u001b[1;32m     91\u001b[0m     seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m     92\u001b[0m     no_graphics\u001b[39m=\u001b[39;49mno_graphics,\n\u001b[1;32m     93\u001b[0m     timeout_wait\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtimeout,\n\u001b[1;32m     94\u001b[0m     additional_args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m     95\u001b[0m     side_channels\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mside_channels,\n\u001b[1;32m     96\u001b[0m     log_folder\u001b[39m=\u001b[39;49mlog_folder,\n\u001b[1;32m     97\u001b[0m )\n\u001b[1;32m     98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreset(arenas_configurations)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/aai/lib/python3.10/site-packages/mlagents_envs/environment.py:236\u001b[0m, in \u001b[0;36mUnityEnvironment.__init__\u001b[0;34m(self, file_name, worker_id, base_port, seed, no_graphics, timeout_wait, additional_args, side_channels, log_folder, num_areas)\u001b[0m\n\u001b[1;32m    228\u001b[0m rl_init_parameters_in \u001b[39m=\u001b[39m UnityRLInitializationInputProto(\n\u001b[1;32m    229\u001b[0m     seed\u001b[39m=\u001b[39mseed,\n\u001b[1;32m    230\u001b[0m     communication_version\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mAPI_VERSION,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    233\u001b[0m     num_areas\u001b[39m=\u001b[39mnum_areas,\n\u001b[1;32m    234\u001b[0m )\n\u001b[1;32m    235\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 236\u001b[0m     aca_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_send_academy_parameters(rl_init_parameters_in)\n\u001b[1;32m    237\u001b[0m     aca_params \u001b[39m=\u001b[39m aca_output\u001b[39m.\u001b[39mrl_initialization_output\n\u001b[1;32m    238\u001b[0m \u001b[39mexcept\u001b[39;00m UnityTimeOutException:\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/aai/lib/python3.10/site-packages/mlagents_envs/environment.py:492\u001b[0m, in \u001b[0;36mUnityEnvironment._send_academy_parameters\u001b[0;34m(self, init_parameters)\u001b[0m\n\u001b[1;32m    490\u001b[0m inputs \u001b[39m=\u001b[39m UnityInputProto()\n\u001b[1;32m    491\u001b[0m inputs\u001b[39m.\u001b[39mrl_initialization_input\u001b[39m.\u001b[39mCopyFrom(init_parameters)\n\u001b[0;32m--> 492\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_communicator\u001b[39m.\u001b[39;49minitialize(inputs, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_poll_process)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/aai/lib/python3.10/site-packages/mlagents_envs/rpc_communicator.py:126\u001b[0m, in \u001b[0;36mRpcCommunicator.initialize\u001b[0;34m(self, inputs, poll_callback)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39minitialize\u001b[39m(\n\u001b[1;32m    124\u001b[0m     \u001b[39mself\u001b[39m, inputs: UnityInputProto, poll_callback: Optional[PollCallback] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    125\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m UnityOutputProto:\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpoll_for_timeout(poll_callback)\n\u001b[1;32m    127\u001b[0m     aca_param \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munity_to_external\u001b[39m.\u001b[39mparent_conn\u001b[39m.\u001b[39mrecv()\u001b[39m.\u001b[39munity_output\n\u001b[1;32m    128\u001b[0m     message \u001b[39m=\u001b[39m UnityMessageProto()\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/aai/lib/python3.10/site-packages/mlagents_envs/rpc_communicator.py:111\u001b[0m, in \u001b[0;36mRpcCommunicator.poll_for_timeout\u001b[0;34m(self, poll_callback)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    109\u001b[0m     \u001b[39mif\u001b[39;00m poll_callback:\n\u001b[1;32m    110\u001b[0m         \u001b[39m# Fire the callback - if it detects something wrong, it should raise an exception.\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m         poll_callback()\n\u001b[1;32m    113\u001b[0m \u001b[39m# Got this far without reading any data from the connection, so it must be dead.\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39mraise\u001b[39;00m UnityTimeOutException(\n\u001b[1;32m    115\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mThe Unity environment took too long to respond. Make sure that :\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    116\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39m The environment does not need user interaction to launch\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mby either passing --no-graphics option or build your Unity executable as server build.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    121\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/aai/lib/python3.10/site-packages/mlagents_envs/environment.py:418\u001b[0m, in \u001b[0;36mUnityEnvironment._poll_process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[39mif\u001b[39;00m poll_res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     exc_msg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_returncode_to_env_message(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process\u001b[39m.\u001b[39mreturncode)\n\u001b[0;32m--> 418\u001b[0m     \u001b[39mraise\u001b[39;00m UnityEnvironmentException(exc_msg)\n",
      "\u001b[0;31mUnityEnvironmentException\u001b[0m: Environment shut down with return code -9 (SIGKILL)."
     ]
    }
   ],
   "source": [
    "random.seed(aai_seed) #set seed for random action selection\n",
    "\n",
    "port = 5005 + random.randint(\n",
    "    0, 1000\n",
    ")  # use a random port to avoid problems if a previous version exits slowly\n",
    "\n",
    "aai_env = AnimalAIEnvironment( \n",
    "    inference=agent_inference,\n",
    "    seed = aai_seed,\n",
    "    log_folder = log_folder_path,\n",
    "    worker_id=aai_seed,\n",
    "    file_name=env_path,\n",
    "    arenas_configurations=configuration_file,\n",
    "    base_port=port,\n",
    "    useCamera=False, # uses raycasts instaed\n",
    "    #resolution=36,\n",
    "    useRayCasts=True,\n",
    "    raysPerSide = int((NUM_RAYS-1)/2),\n",
    "    rayMaxDegrees = 30\n",
    ")\n",
    "\n",
    "#env = UnityToGymWrapper(aai_env, uint8_visual=False, allow_multiple_obs=False, flatten_branched=True)\n",
    "\n",
    "obs = aai_env.reset()\n",
    "\n",
    "braitenbergAgent = Braitenberg(NUM_RAYS, STEP_LENGTH)\n",
    "behavior = list(aai_env.behavior_specs.keys())[0] # by default should be AnimalAI?team=0\n",
    "\n",
    "reward_list = []\n",
    "firststep = True\n",
    "for _episode in range(NUM_EPISODES): #Run episodes with the Braitenberg-style agent\n",
    "    if firststep:\n",
    "        aai_env.step() # Need to make a first step in order to get an observation.\n",
    "        firstep = False\n",
    "    dec, term = aai_env.get_steps(behavior)\n",
    "    done = False\n",
    "    episodeReward = 0\n",
    "    while not done:\n",
    "        raycasts = aai_env.get_obs_dict(dec.obs)[\"rays\"] # Get the raycast data\n",
    "        # print(braitenbergAgent.prettyPrint(raycasts)) #print raycasts in more readable format\n",
    "        movement = aai_env.get_obs_dict(dec.obs)[\"position\"]\n",
    "        # print(movement)\n",
    "        action = braitenbergAgent.get_action(raycasts, STEP_LENGTH)\n",
    "        # print(action)\n",
    "        aai_env.set_actions(behavior, action.action_tuple)\n",
    "        aai_env.step()      \n",
    "        dec, term = aai_env.get_steps(behavior)\n",
    "        if len(dec.reward) > 0:\n",
    "            episodeReward += dec.reward\n",
    "        if len(term) > 0: #Episode is over\n",
    "            episodeReward += term.reward\n",
    "            print(F\"Episode Reward: {episodeReward}\")\n",
    "            reward_list.append(episodeReward)\n",
    "            done = True\n",
    "            firststep = True\n",
    "aai_env.close()\n",
    "\n",
    "reward_df = pd.DataFrame(reward_list, columns = ['finalRewards'])\n",
    "\n",
    "csv_path = log_folder_path + \"/\" + agent_name + \"_NumRays_\" + str(NUM_RAYS) + \"_Seed_\" + str(aai_seed) + \"_StepLength_\" + str(STEP_LENGTH) + \".csv\"\n",
    "reward_df.to_csv(csv_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aai_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a43ad5049bc12cdb7a231109f90c0e4b3912f1bf6225b3b59bbf4f1bf238a4ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
