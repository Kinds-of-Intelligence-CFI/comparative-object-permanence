{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from animalai.envs.actions import AAIActions, AAIAction\n",
    "from animalai.envs.raycastparser import RayCastParser\n",
    "from animalai.envs.raycastparser import RayCastObjects\n",
    "from animalai.envs.environment import AnimalAIEnvironment\n",
    "from gym_unity.envs import UnityToGymWrapper\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import NamedTuple, Dict, Optional, List\n",
    "\n",
    "#Braitenberg vehicle 1) Moves a few steps forward [to avoid clear walls] 2) Moves towards walls 3) Moves a few steps randomly 4)Moves towards target [which will hopefully be in sight and they will not be stuck by a wall]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aai_seed = random.randint(\n",
    "    0, 10000\n",
    ") # set the seed for the random number generator, and then vary this to make a population of agents\n",
    "\n",
    "NUM_RAYS = 7 # number of rays to use in raycast, see here: https://github.com/Kinds-of-Intelligence-CFI/animal-ai/blob/main/docs/observations.md\n",
    "STEP_LENGTH = 5 # how many steps to take before taking a random action, vary this to make a population of agents\n",
    "NUM_EPISODES = 18 # add number of episodes for testing\n",
    "\n",
    "agent_inference = True\n",
    "\n",
    "agent_name = \"BraitenbergVehicle\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_file = r\"C:\\Users\\Lenovo\\OneDrive\\Documents\\University\\Year 3\\Dissertation Project\\Stats\\Agents\\.yml\"\n",
    "env_path = r\"C:\\Users\\Lenovo\\OneDrive\\Documents\\University\\Year 3\\Dissertation Project\\Experiment\\NewBuildDevWIN\"\n",
    "log_folder_path = r\"C:\\Users\\Lenovo\\OneDrive\\Documents\\University\\Year 3\\Dissertation Project\\Stats\\Agents\\BenchmarkAgentsResults\\BraitenbergAgent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Braitenberg vehicle design by M. D. Crosby.\n",
    "# Adapted by K. Voudouris where noted.\n",
    "# Futher adapted by N. Siwinska \n",
    "\n",
    "class Braitenberg():\n",
    "    \"\"\"Implements a simple Braitenberg vehicle agent that heads towards food\n",
    "    Can change the number of rays but only responds to GOODGOALs, GOODGOALMULTI and BADGOAL\"\"\"\n",
    "    def __init__(self, no_rays, step_length):\n",
    "        self.no_rays = no_rays\n",
    "        assert(self.no_rays % 2 == 1), \"Only supports odd number of rays (but environment should only allow odd number)\"\n",
    "        \n",
    "        self.step_length = step_length\n",
    "        assert(self.step_length >= 1), \"Only supports step lengths greater than or equal to 1\"\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        Note that BADGOAL includes both red goals AND death zones.\n",
    "        \"\"\"\n",
    "        self.listOfObjects = [RayCastObjects.GOODGOAL, RayCastObjects.GOODGOALMULTI, RayCastObjects.BADGOAL, RayCastObjects.IMMOVABLE]\n",
    "        self.raycast_parser = RayCastParser([RayCastObjects.GOODGOAL, RayCastObjects.GOODGOALMULTI, RayCastObjects.BADGOAL, RayCastObjects.IMMOVABLE], self.no_rays)\n",
    "        self.actions = AAIActions()\n",
    "        self.prev_action = self.actions.NOOP\n",
    "\n",
    "    def prettyPrint(self, obs) -> str:\n",
    "        \"\"\"Prints the parsed observation\"\"\"\n",
    "        return self.raycast_parser.prettyPrint(obs)\n",
    "    \n",
    "    def get_action(self, obs, step_length) -> AAIAction:\n",
    "        \"\"\"Returns the action to take given the current parsed raycast observation\"\"\"\n",
    "        obs = self.raycast_parser.parse(obs)\n",
    "        newAction = self.actions.NOOP\n",
    "        if self.ahead(obs, RayCastObjects.GOODGOAL):\n",
    "            newAction = self.actions.FORWARDS\n",
    "        elif self.left(obs, RayCastObjects.GOODGOAL):\n",
    "            newAction = self.actions.FORWARDSLEFT\n",
    "        elif self.right(obs, RayCastObjects.GOODGOAL):\n",
    "            newAction = self.actions.FORWARDSRIGHT\n",
    "        #elif self.ahead(obs, RayCastObjects.BADGOAL):\n",
    "            #newAction = self.actions.BACKWARDS\n",
    "        #elif self.left(obs, RayCastObjects.BADGOAL):\n",
    "            #newAction = self.actions.BACKWARDSLEFT\n",
    "        #elif self.right(obs, RayCastObjects.BADGOAL):\n",
    "            #newAction = self.actions.BACKWARDSRIGHT\n",
    "        else:\n",
    "            #If the agent is not at or further than the y=1.3 coordinate (as there is no advantage to random movement when there are clear walls on either side), the direction it should take is straight. \n",
    "            if np.array(movement[1] > 1.3) == True: \n",
    "                newAction = self.actions.FORWARDS\n",
    "            #if self.prev_action == self.actions.NOOP or self.prev_action == self.actions.BACKWARDS:\n",
    "            take_steps = random.randint(0, step_length) \n",
    "            if take_steps != 0:\n",
    "                newAction = self.prev_action\n",
    "                rand_action = random.randint(0,15) # pick either random actions (56% chance) or reactions based on sensing immovable objects straight ahead (44% chance) \n",
    "                if  (rand_action == 0):\n",
    "                    newAction = self.actions.NOOP\n",
    "                elif (rand_action == 1):\n",
    "                    newAction = self.actions.FORWARDS\n",
    "                elif (rand_action == 2): \n",
    "                    newAction = self.actions.FORWARDSRIGHT\n",
    "                elif (rand_action == 3):\n",
    "                    newAction = self.actions.RIGHT\n",
    "                elif (rand_action == 4):\n",
    "                    newAction = self.actions.BACKWARDSRIGHT\n",
    "                elif (rand_action == 5):\n",
    "                    newAction = self.actions.BACKWARDS\n",
    "                elif (rand_action == 6):\n",
    "                    newAction = self.actions.BACKWARDSLEFT\n",
    "                elif (rand_action == 7):\n",
    "                    newAction = self.actions.LEFT\n",
    "                elif (rand_action == 8):\n",
    "                    newAction = self.actions.FORWARDSLEFT\n",
    "                elif (rand_action == 9 or 10 or 11 or 12 or 13 or 14 or 15):\n",
    "                    if self.ahead(obs, RayCastObjects.IMMOVABLE):\n",
    "                        #If an object is sensed in front,then perform random actions as per the chances given;\n",
    "                        newAction = self.prev_action\n",
    "                        rand_action_wall = random.randint(0,10) # pick one of 6 actions randomly, with the highest chance being a forward movement (55% forwards left, forwards right or forwards)\n",
    "                        if  (rand_action_wall == 0 ):\n",
    "                            newAction = self.actions.BACKWARDS\n",
    "                        elif (rand_action_wall == 1 or 2):\n",
    "                            newAction = self.actions.FORWARDSRIGHT\n",
    "                        elif (rand_action_wall == 3 or 4): \n",
    "                            newAction = self.actions.FORWARDSLEFT\n",
    "                        elif (rand_action_wall == 5):\n",
    "                            newAction = self.actions.BACKWARDSLEFT\n",
    "                        elif (rand_action_wall == 6): \n",
    "                            newAction = self.actions.BACKWARDSRIGHT\n",
    "                        elif (rand_action_wall == 7):\n",
    "                            newAction = self.actions.LEFT\n",
    "                        elif (rand_action_wall == 8):\n",
    "                            newAction = self.actions.RIGHT\n",
    "                        elif (rand_action_wall == 9 or 10):\n",
    "                            newAction = self.actions.FORWARDS\n",
    "                    elif self.left(obs, RayCastObjects.IMMOVABLE):\n",
    "                        newAction = self.actions.FORWARDSLEFT\n",
    "                    elif self.right(obs, RayCastObjects.IMMOVABLE):\n",
    "                        newAction = self.actions.FORWARDSRIGHT\n",
    "                    elif self.ahead(obs, RayCastObjects.BADGOAL):\n",
    "                        newAction = self.actions.BACKWARDS\n",
    "                    elif self.left(obs, RayCastObjects.BADGOAL):\n",
    "                        newAction = self.actions.BACKWARDSLEFT\n",
    "                    elif self.right(obs, RayCastObjects.BADGOAL):\n",
    "                        newAction = self.actions.BACKWARDSRIGHT\n",
    "            #    newAction = self.prev_action  \n",
    "            #elif self.ahead(obs, RayCastObjects.BADGOAL):\n",
    "                #newAction = self.actions.BACKWARDS\n",
    "            #elif self.left(obs, RayCastObjects.BADGOAL):\n",
    "                #newAction = self.actions.BACKWARDSLEFT\n",
    "            #elif self.right(obs, RayCastObjects.BADGOAL):\n",
    "                #newAction = self.actions.BACKWARDSRIGHT\n",
    "        self.prev_action = newAction\n",
    "        return newAction\n",
    "        \n",
    "\n",
    "\n",
    "    def ahead(self, obs, object):\n",
    "        \"\"\"Returns true if the input object is ahead of the agent\"\"\"\n",
    "        if(obs[self.listOfObjects.index(object)][int((self.no_rays-1)/2)] > 0):\n",
    "            # print(\"found \" + str(object) + \" ahead\")\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def left(self, obs, object):\n",
    "        \"\"\"Returns true if the input object is left of the agent\"\"\"\n",
    "        for i in range(int((self.no_rays-1)/2)):\n",
    "            if(obs[self.listOfObjects.index(object)][i] > 0):\n",
    "                # print(\"found \" + str(object) + \" left\")\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def right(self, obs, object):\n",
    "        \"\"\"Returns true if the input object is right of the agent\"\"\"\n",
    "        for i in range(int((self.no_rays-1)/2)):\n",
    "            if(obs[self.listOfObjects.index(object)][i+int((self.no_rays-1)/2) + 1] > 0):\n",
    "                # print(\"found \" + str(object) + \" right\")\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: [-1.000187]\n"
     ]
    },
    {
     "ename": "UnityCommunicatorStoppedException",
     "evalue": "Communicator has exited.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnityCommunicatorStoppedException\u001b[0m         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 31>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;66;03m# print(action)\u001b[39;00m\n\u001b[0;32m     45\u001b[0m aai_env\u001b[38;5;241m.\u001b[39mset_actions(behavior, action\u001b[38;5;241m.\u001b[39maction_tuple)\n\u001b[1;32m---> 46\u001b[0m \u001b[43maai_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m      \n\u001b[0;32m     47\u001b[0m dec, term \u001b[38;5;241m=\u001b[39m aai_env\u001b[38;5;241m.\u001b[39mget_steps(behavior)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(dec\u001b[38;5;241m.\u001b[39mreward) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\animalai\\lib\\site-packages\\mlagents_envs\\timers.py:305\u001b[0m, in \u001b[0;36mtimed.<locals>.wrapped\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m hierarchical_timer(func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m):\n\u001b[1;32m--> 305\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\animalai\\lib\\site-packages\\mlagents_envs\\environment.py:350\u001b[0m, in \u001b[0;36mUnityEnvironment.step\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    348\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_communicator\u001b[38;5;241m.\u001b[39mexchange(step_input, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll_process)\n\u001b[0;32m    349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 350\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UnityCommunicatorStoppedException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCommunicator has exited.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    351\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_behavior_specs(outputs)\n\u001b[0;32m    352\u001b[0m rl_output \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mrl_output\n",
      "\u001b[1;31mUnityCommunicatorStoppedException\u001b[0m: Communicator has exited."
     ]
    }
   ],
   "source": [
    "random.seed(aai_seed) #set seed for random action selection\n",
    "\n",
    "port = 5005 + random.randint(\n",
    "    0, 1000\n",
    ")  # use a random port to avoid problems if a previous version exits slowly\n",
    "\n",
    "aai_env = AnimalAIEnvironment( \n",
    "    inference=agent_inference,\n",
    "    seed = aai_seed,\n",
    "    log_folder = log_folder_path,\n",
    "    worker_id=aai_seed,\n",
    "    file_name=env_path,\n",
    "    arenas_configurations=configuration_file,\n",
    "    base_port=port,\n",
    "    useCamera=False, # uses raycasts instaed\n",
    "    #resolution=36,\n",
    "    useRayCasts=True,\n",
    "    raysPerSide = int((NUM_RAYS-1)/2),\n",
    "    rayMaxDegrees = 30\n",
    ")\n",
    "\n",
    "#env = UnityToGymWrapper(aai_env, uint8_visual=False, allow_multiple_obs=False, flatten_branched=True)\n",
    "\n",
    "obs = aai_env.reset()\n",
    "\n",
    "braitenbergAgent = Braitenberg(NUM_RAYS, STEP_LENGTH)\n",
    "behavior = list(aai_env.behavior_specs.keys())[0] # by default should be AnimalAI?team=0\n",
    "\n",
    "reward_list = []\n",
    "firststep = True\n",
    "for _episode in range(NUM_EPISODES): #Run episodes with the Braitenberg-style agent\n",
    "    if firststep:\n",
    "        aai_env.step() # Need to make a first step in order to get an observation.\n",
    "        firstep = False\n",
    "    dec, term = aai_env.get_steps(behavior)\n",
    "    done = False\n",
    "    episodeReward = 0\n",
    "    while not done:\n",
    "        raycasts = aai_env.get_obs_dict(dec.obs)[\"rays\"] # Get the raycast data\n",
    "        # print(braitenbergAgent.prettyPrint(raycasts)) #print raycasts in more readable format\n",
    "        movement = aai_env.get_obs_dict(dec.obs)[\"position\"]\n",
    "        # print(movement)\n",
    "        action = braitenbergAgent.get_action(raycasts, STEP_LENGTH)\n",
    "        # print(action)\n",
    "        aai_env.set_actions(behavior, action.action_tuple)\n",
    "        aai_env.step()      \n",
    "        dec, term = aai_env.get_steps(behavior)\n",
    "        if len(dec.reward) > 0:\n",
    "            episodeReward += dec.reward\n",
    "        if len(term) > 0: #Episode is over\n",
    "            episodeReward += term.reward\n",
    "            print(F\"Episode Reward: {episodeReward}\")\n",
    "            reward_list.append(episodeReward)\n",
    "            done = True\n",
    "            firststep = True\n",
    "aai_env.close()\n",
    "\n",
    "reward_df = pd.DataFrame(reward_list, columns = ['finalRewards'])\n",
    "\n",
    "csv_path = log_folder_path + \"/\" + agent_name + \"_NumRays_\" + str(NUM_RAYS) + \"_Seed_\" + str(aai_seed) + \"_StepLength_\" + str(STEP_LENGTH) + \".csv\"\n",
    "reward_df.to_csv(csv_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aai_env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a43ad5049bc12cdb7a231109f90c0e4b3912f1bf6225b3b59bbf4f1bf238a4ec"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
