{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PPO evaluation script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import time\n",
    "import torch as th\n",
    "import pandas as pd\n",
    "\n",
    "from stable_baselines3 import PPO\n",
    "from mlagents_envs.envs.unity_gym_env import UnityToGymWrapper\n",
    "from animalai.envs.environment import AnimalAIEnvironment\n",
    "\n",
    "\n",
    "from animalai.envs.environment import AnimalAIEnvironment\n",
    "from animalai.envs.actions import AAIActions, AAIAction\n",
    "#from gym_unity.envs import UnityToGymWrapper\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from yamlHandling import find_yaml_files #this function finds the yaml files in a directory.\n",
    "from yamlHandling import yaml_combinor #this function combines a batch of yaml files and saves the output in a temporary folder. This means we can run inference on batches of tests at once.\n",
    "from mysqlConnection import databaseConnector #this function permits connection to a mysql database using a CSV file containing details of the db connection.\n",
    "from mysqlConnection import agentToDB #this function takes a dictionary and ingresses it into a table\n",
    "from mysqlConnection import removePreviouslyRunInstances #this function takes a set of yaml files and task names and removes any that have already got results in the database.\n",
    "from mysqlConnection import selectID #this function finds the integer ID for a table given a particular column name and value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection\n",
    "\n",
    "A function for connecting to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "mycursor.close()\n",
    "\n",
    "print(\"Connection checked and closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths\n",
    "\n",
    "Provide the paths to the directory containing the configs being tested over, as well as the path the animal ai environment. Provide a location for generating temporary files of combined configs. This defaults to the parent directory of the github repository, to prevent results being pushed accidentally. Finally, provide the location of the saved PPO model in the modelsaves folder (gitignored)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_folder = \"../../configs/tests_agents\"\n",
    "\n",
    "#env_path = \"../../env/AnimalAI\"\n",
    "env_path = \"C:/Users/kv301/Documents/animal-ai/env/AnimalAI.exe\"\n",
    "\n",
    "temp_folder_location = \"../../..\"\n",
    "\n",
    "ppo_model_save_location = \"../modelsaves/modelsaves/sanity_green_test/model_1000\" #a dummy file (64x64 CNN trained for 1000 steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add All Tasks In Directory To Database\n",
    "\n",
    "Iterate through the directory and find yaml files and their task names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerunInstanceTable = False\n",
    "\n",
    "mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "yaml_files, task_names = find_yaml_files(configuration_folder)\n",
    "\n",
    "if rerunInstanceTable:\n",
    "    dropTable = \"DROP TABLE IF EXISTS ppoinstanceresults, ppointrainstanceresults, instances;\"\n",
    "    mycursor.execute(dropTable)\n",
    "    \n",
    "    sql = \"CREATE TABLE instances(instanceid INT AUTO_INCREMENT PRIMARY KEY, instancename VARCHAR(750) UNIQUE NOT NULL);\"\n",
    "    mycursor.execute(sql)\n",
    "\n",
    "for instance in task_names:\n",
    "    try:\n",
    "        insertQuery = \"INSERT INTO instances(instancename) VALUES('\" + str(instance) + \"');\"\n",
    "        mycursor.execute(insertQuery)\n",
    "        connection.commit()\n",
    "    except:\n",
    "        print(f\"Task {instance} has already been added to this table. Moving to next.\")\n",
    "\n",
    "mycursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Agent Table\n",
    "\n",
    "Create a table that stores details about the agent. Currently just storing a single agent, but easily scalable to multiple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerunAgentTable = True\n",
    "\n",
    "mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "if rerunAgentTable:\n",
    "    dropTable = \"DROP TABLE IF EXISTS  ppoagents, ppoagentinstanceresults, ppoagentintrainstanceresults;\"\n",
    "    mycursor.execute(dropTable)\n",
    "    \n",
    "    sql = \"CREATE TABLE `ppoagents` (`agentid` INT AUTO_INCREMENT PRIMARY KEY, `agent_tag` VARCHAR(300), `aai_seed` INT, `policy` VARCHAR(10), `aai_env_version` VARCHAR(20), `learning_rate` FLOAT(8), `n_steps_training` INT, `batch_size` INT, `n_epochs` INT, `gamma` FLOAT(8), `gae_lambda` FLOAT(8), `clip_range` FLOAT(8), `clip_range_vf` VARCHAR(10), `normalize_advantage` BOOL, `ent_coef` FLOAT(8), `vf_coef` FLOAT(8), `max_grad_norm` FLOAT(8), use_sde BOOL, sde_sample_freq FLOAT(8), `target_kl` VARCHAR(10), stats_window_size FLOAT(8), `training_curriculum` VARCHAR(100), `state_size` INT, `act_func` VARCHAR(30), UNIQUE(agent_tag, aai_seed, training_curriculum));\"\n",
    "    mycursor.execute(sql)\n",
    "\n",
    "mycursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_agent_dict = {\n",
    "    \"policy\" : \"CNN\", #or \"MLP\" for raycasts\n",
    "    \"aai_env_version\" : \"aai.3.1.3\",\n",
    "    \"learning_rate\" : 0.0003,\n",
    "    \"n_steps_training\" : 1000,\n",
    "    \"batch_size\" : 64,\n",
    "    \"n_epochs\" : 10,\n",
    "    \"gamma\" : 0.99,\n",
    "    \"gae_lambda\" : 0.95,\n",
    "    \"clip_range\" : 0.2,\n",
    "    \"clip_range_vf\" : \"None\", #must be string, not int/float\n",
    "    \"normalize_advantage\" : True,\n",
    "    \"ent_coef\" : 0,\n",
    "    \"vf_coef\" : 0.5,\n",
    "    \"max_grad_norm\" : 0.5,\n",
    "    \"use_sde\" : False,\n",
    "    \"sde_sample_freq\" : -1,\n",
    "    \"target_kl\" : \"None\", #must be string, not int/float\n",
    "    \"stats_window_size\" : 100,\n",
    "\n",
    "    \"training_curriculum\" : \"sanity_green_random\", #which training curriculum was the agent trained on?\n",
    "    \"agent_tag\" : \"sanitygreen_ppo_1000_64x64\",\n",
    "    \"state_size\" : 64, #what is the size of the state (64x64)\n",
    "    \"act_func\" : \"ReLU\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_dict_list = [ppo_agent_dict]\n",
    "\n",
    "seeds_to_run = [2023] #one seed to limit compute/time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "for agent in agent_dict_list:\n",
    "    for seed in seeds_to_run:\n",
    "        agent['aai_seed'] = seed\n",
    "        agentToDB(mycursor, agent, table_name = \"ppoagents\")\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "mycursor.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference And Store\n",
    "\n",
    "Run saved PPO agent on configuration files and store results in database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "rebuildInstanceResultsTables = True\n",
    "\n",
    "if rebuildInstanceResultsTables:\n",
    "    print(\"Rebuilding results tables, dropping if they already exist.\")\n",
    "\n",
    "    dropInstanceResultsTables = \"DROP TABLE IF EXISTS ppoagentinstanceresults, ppoagentintrainstanceresults;\"\n",
    "    mycursor.execute(dropInstanceResultsTables)\n",
    "    \n",
    "    createInstanceTable = \"CREATE TABLE ppoagentinstanceresults(instanceid INT NOT NULL, agentid INT NOT NULL, finalreward FLOAT(53), FOREIGN KEY (instanceid) REFERENCES instances(instanceid), FOREIGN KEY(agentid) REFERENCES ppoagents(agentid), PRIMARY KEY (instanceid, agentid));\"\n",
    "    mycursor.execute(createInstanceTable)\n",
    "\n",
    "    createIntraInstanceTable = \"CREATE TABLE ppoagentintrainstanceresults(instanceid INT NOT NULL, agentid INT NOT NULL, step INT NOT NULL, actiontaken INT NOT NULL, stepreward FLOAT(53), xvelocity FLOAT(32), yvelocity FLOAT(32), zvelocity FLOAT(32), xpos FLOAT(32), ypos FLOAT(32), zpos FLOAT(32), FOREIGN KEY (instanceid) REFERENCES instances(instanceid), FOREIGN KEY(agentid) REFERENCES ppoagents(agentid), PRIMARY KEY(instanceid, agentid, step));\"\n",
    "    mycursor.execute(createIntraInstanceTable)\n",
    "\n",
    "    print(\"Tables: ppoagentinstanceresults and ppointrainstanceresults have been successfully built.\")\n",
    "\n",
    "mycursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPPOAndStore (cur, con, model_save_path, batch_size: int, agent_dict: dict, yaml_files, task_names, temp_folder_location, agent_inference = False, port_base = 6600, randomise_port = True, verbose = True):\n",
    "    \n",
    "    # first, check if this agent has been added to the DB already\n",
    "\n",
    "    agentid = selectID(cur, id_name = \"agentid\", table_name = \"ppoagents\", WHERE_column = \"agent_tag\", WHERE_clause = agent_dict['agent_tag'], secondary_WHERE_column = \"aai_seed\", secondary_WHERE_clause = agent_dict['aai_seed'])\n",
    "    \n",
    "    try:\n",
    "        task_names, yaml_files = removePreviouslyRunInstances(cur = cur, yaml_files=yaml_files, task_names=task_names, agentid=agentid, agent_table = \"ppoagents\", agent_instance_results_table = \"ppoagentinstanceresults\")\n",
    "    except:\n",
    "        print(\"Running on all files.\")\n",
    "\n",
    "    # now proceed with testing\n",
    "    yaml_index = 0\n",
    "\n",
    "    if randomise_port:\n",
    "\n",
    "        port = port_base + yaml_index + random.randint( #create random base port.\n",
    "            0, 9000\n",
    "            )\n",
    "        \n",
    "    else:\n",
    "        port = port_base + yaml_index\n",
    "        \n",
    "    batch_counter = 0\n",
    "\n",
    "    #set seed\n",
    "    random.seed(agent_dict['aai_seed'])\n",
    "\n",
    "    #load agent\n",
    "    model = PPO.load(model_save_path)\n",
    "\n",
    "    if len(yaml_files) > 0:\n",
    "        for yaml_index in range(0, len(yaml_files), batch_size):\n",
    "\n",
    "            if (yaml_index + batch_size) > len(yaml_files) or batch_size > len(yaml_files):\n",
    "                upper_bound = len(yaml_files)\n",
    "            else:\n",
    "                upper_bound = ((yaml_index + batch_size))\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Running inferences on batch {batch_counter + 1} of {batch_size} files of total {len(yaml_files)}. {len(yaml_files) - (batch_size * (batch_counter + 1))} instances to go.\")\n",
    "\n",
    "            batch_files = yaml_files[yaml_index:upper_bound]\n",
    "\n",
    "            batch_file_names = task_names[yaml_index:upper_bound]\n",
    "\n",
    "            batch_temp_file_name = f\"TempConfig_{agent_dict['agent_tag']}_{agent_dict['aai_seed']}_{yaml_index}.yml\"\n",
    "\n",
    "            config_file_path = yaml_combinor(file_list = batch_files, temp_file_location=temp_folder_location, stored_file_name = batch_temp_file_name)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Opening AAI Environment.\")\n",
    "\n",
    "            temp_port = port + yaml_index # increment through ports to prevent calling the same socket.\n",
    "\n",
    "            aai_env = AnimalAIEnvironment( \n",
    "                inference=agent_inference, #Set true when watching the agent\n",
    "                seed = agent_dict['aai_seed'],\n",
    "                worker_id=agent_dict['aai_seed'],\n",
    "                file_name=env_path,\n",
    "                arenas_configurations=config_file_path,\n",
    "                base_port=temp_port,\n",
    "                useCamera=True,\n",
    "                resolution=agent_dict['state_size'], #make resolution small to improve processing speed - random walkers don't need anything.\n",
    "                useRayCasts=False,\n",
    "                timescale=1,\n",
    "                no_graphics=False\n",
    "            )\n",
    "\n",
    "            env = UnityToGymWrapper(aai_env, uint8_visual=True, allow_multiple_obs=True, flatten_branched=True)\n",
    "\n",
    "            obs = env.reset()\n",
    "            print(obs)\n",
    "\n",
    "            for _instance in range(len(batch_files)): \n",
    "\n",
    "                #get instance ID\n",
    "                instanceid = selectID(cur, id_name = \"instanceid\", table_name = \"instances\", WHERE_column = \"instancename\", WHERE_clause = batch_file_names[_instance])\n",
    "\n",
    "                #prepare to run instance\n",
    "                done = False\n",
    "\n",
    "                episodeReward = 0\n",
    "\n",
    "                step_counter = 0\n",
    "    \n",
    "                while not done:\n",
    "\n",
    "                    action, _state = model.predict(obs[0], deterministic=False)\n",
    "                    obs, reward, done, info = env.step(action.item())\n",
    "                    episodeReward += reward\n",
    "                    step_counter += 1\n",
    "                    env.render()\n",
    "\n",
    "                    try:\n",
    "                        intraInstanceQuery = f\"INSERT INTO ppoagentintrainstanceresults(instanceid, agentid, step, actiontaken, stepreward, xvelocity, yvelocity, zvelocity, xpos, ypos, zpos) VALUES ({instanceid}, {agentid}, {step_counter}, {action}, {float(episodeReward)}, {obs[1][1]}, {obs[1][2]}, {obs[1][3]}, {obs[1][4]}, {obs[1][5]}, {obs[1][6]});\"\n",
    "                        cur.execute(intraInstanceQuery)\n",
    "                        #con.commit()\n",
    "         \n",
    "                    except:\n",
    "                        print(f\"There's something wrong with this step. Here's the query {intraInstanceQuery}\")\n",
    "                        pass\n",
    "\n",
    "                    if done:\n",
    "                        if verbose:\n",
    "                            print(F\"Episode Reward: {episodeReward}\")\n",
    "                        obs = env.reset()\n",
    "                        break #to be sure\n",
    "                \n",
    "                try:\n",
    "                    insertInstanceResults = f\"INSERT INTO ppoagentinstanceresults(instanceid, agentid, finalreward) VALUES ({instanceid}, {agentid}, {episodeReward});\"\n",
    "                    cur.execute(insertInstanceResults)\n",
    "                    con.commit()\n",
    "                except:\n",
    "                    print(\"It looks like this agent has already been tested on this instance.\")\n",
    "    \n",
    "            env.close()\n",
    "\n",
    "            batch_counter += 1\n",
    "\n",
    "            os.remove(config_file_path)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Moving to next batch.\")\n",
    "\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\")\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_on_instance_wrapper(seed, agent, model_save_path, yaml_batch_size=1, port_base = 6600, randomise_port = True, verbose = True):\n",
    "    agent['aai_seed'] = seed\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Running {agent['agent_tag']} on seed {seed}.\")\n",
    "    \n",
    "    mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "    runPPOAndStore(mycursor, connection, model_save_path, yaml_batch_size, agent_dict=agent, yaml_files=yaml_files, task_names=task_names, temp_folder_location=temp_folder_location, agent_inference=True, port_base = port_base, randomise_port = randomise_port, verbose = verbose)\n",
    "\n",
    "    mycursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml_batch_size = 10 #problem with task ordering, so having to do batches of 1. Much slower...\n",
    "counter = 0\n",
    "verbose = True\n",
    "adhoc_port = 4444\n",
    "\n",
    "while counter <= (len(seeds_to_run) * len(agent_dict_list)):\n",
    "    try:\n",
    "        for seed in seeds_to_run:\n",
    "            for agent_dictionary in agent_dict_list:\n",
    "                adhoc_port = (counter+10)*100\n",
    "                run_agent_on_instance_wrapper(seed, agent_dictionary, model_save_path=ppo_model_save_location, yaml_batch_size=yaml_batch_size, port_base = adhoc_port, randomise_port = True, verbose = verbose)\n",
    "                if verbose:\n",
    "                    print(\"Moving to next seed.\")\n",
    "                counter += 1\n",
    "            if counter > (len(seeds_to_run) * len(agent_dict_list)):\n",
    "                break\n",
    "            if verbose:\n",
    "                 print(\"Moving to next agent.\")\n",
    "    except:\n",
    "        print(\"Sockets were occupied. Waiting 10 seconds and starting again.\")\n",
    "        counter = 0\n",
    "        time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animalaiv3.1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
