{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Action Agent Experiments\n",
    "\n",
    "Author: K. Voudouris, 2023 (c) All Rights Reserved.\n",
    "\n",
    "Contact: kv301@cam.ac.uk; k.voudouris14@googlemail.com; [Twitter @KozzyVoudouris](https://twitter.com/KozzyVoudouris); [GitHub @kozzy97](https://github.com/kozzy97)\n",
    "\n",
    "Date: July 2023\n",
    "\n",
    "This script runs a series of random action agents on the object permanence tests and stores the results in a MySQL database. It relies on a few things:\n",
    "\n",
    "1. All the dependencies are installed, particularly that animalai is installed properly. I recommend using a conda environment and setting up an ipykernel for running this notebook.\n",
    "2. AnimalAI is installed as an executable in the `env` folder.\n",
    "3. A recent installation of MySQL, configured with a database, user, and password, as well as the local (or remote) address to store on. MySQL WorkBench is a good IDE for interacting with MySQL (this was created with WorkBench 8.0)\n",
    "4. A CSV file in the same directory as this notebook called `databaseConnectionDetails.csv`, containing columns `database_name`, `hostname`, `username`, and `password` for database connection, with the values in the next row. This is gitignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keyboard\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "from animalai.envs.environment import AnimalAIEnvironment\n",
    "from animalai.envs.actions import AAIActions, AAIAction\n",
    "from gym_unity.envs import UnityToGymWrapper\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from randomActionAgents import RandomActionAgent #import the random walker class\n",
    "from yamlHandling import find_yaml_files #this function finds the yaml files in a directory.\n",
    "from yamlHandling import yaml_combinor #this function combines a batch of yaml files and saves the output in a temporary folder. This means we can run inference on batches of tests at once.\n",
    "from mysqlConnection import databaseConnector #this function permits connection to a mysql database using a CSV file containing details of the db connection.\n",
    "from mysqlConnection import agentToDB #this function takes a dictionary and ingresses it into a table\n",
    "from mysqlConnection import removePreviouslyRunInstances #this function takes a set of yaml files and task names and removes any that have already got results in the database.\n",
    "from mysqlConnection import selectID #this function finds the integer ID for a table given a particular column name and value"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Database Connection\n",
    "\n",
    "A function for connecting to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "mycursor.close()\n",
    "\n",
    "print(\"Connection checked and closed.\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Paths\n",
    "\n",
    "Provide the paths to the directory containing the configs being tested over, as well as the path the animal ai environment. Finally, provide a location for generating temporary files of combined configs. This defaults to the parent directory of the github repository, to prevent results being pushed accidentally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "configuration_folder = \"../../configs/tests_agents\"\n",
    "\n",
    "env_path = \"../../env/AnimalAI\"\n",
    "\n",
    "temp_folder_location = \"../../..\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add All Tasks In Directory To Database\n",
    "\n",
    "Iterate through the directory and find yaml files and their task names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerunInstanceTable = False\n",
    "\n",
    "mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "yaml_files, task_names = find_yaml_files(configuration_folder)\n",
    "\n",
    "if rerunInstanceTable:\n",
    "    dropTable = \"DROP TABLE IF EXISTS randomactionagentinstanceresults, randomactionagentintrainstanceresults, instances;\"\n",
    "    mycursor.execute(dropTable)\n",
    "    \n",
    "    sql = \"CREATE TABLE instances(instanceid INT AUTO_INCREMENT PRIMARY KEY, instancename VARCHAR(750) UNIQUE NOT NULL);\"\n",
    "    mycursor.execute(sql)\n",
    "\n",
    "for instance in task_names:\n",
    "    try:\n",
    "        insertQuery = \"INSERT INTO instances(instancename) VALUES('\" + str(instance) + \"');\"\n",
    "        mycursor.execute(insertQuery)\n",
    "        connection.commit()\n",
    "    except:\n",
    "        print(f\"Task {instance} has already been added to this table. Moving to next.\")\n",
    "\n",
    "mycursor.close()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "Dictionaries of parameters to define some random action agents. These agents randomly sample an action from the set of nine possible actions, and then they pick a number of steps to execute that action from a series of different distributions. Biases can be introduced to favour the selection of certain actions, as well as correlations with previous actions. These agents more closely resemble if a human were to randomly press buttons to try to get a reward, or if an artificial agent was selecting actions from a random policy. However, their behaviours is less easily described than the randomWalker agents, for which there is plenty of work outlining expected trajectories and behaviours.\n",
    "\n",
    "The first agent selects number of steps from a uniform distribution. There are no biases or correlations for action selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniform_action_agent = {'step_length_distribution' : 'uniform',\n",
    "                       'max_step_length' : 20,\n",
    "                       '0stationaryactionbias' : 1,\n",
    "                       '1rturnbias' : 1,\n",
    "                       '2lturnbias' : 1,\n",
    "                       '3forwardbias' : 1,\n",
    "                       '4forwardrbias' : 1,\n",
    "                       '5forwardlbias' : 1,\n",
    "                       '6backwardbias' : 1,\n",
    "                       '7backwardlbias' : 1,\n",
    "                       '8backwardrbias' : 1,\n",
    "                       'remove_prev_step': False,\n",
    "                       'aai_seed' : 2023,\n",
    "                       'agent_tag' : 'Random Action Agent no bias no correlation uniform step length max 20'}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second agent selects actions with a bias towards going forwards, simulating a cephalo-caudal bias whereby animals tend to go forwards rather than stop, turn, or reverse. Number of steps is selected from a cauchy distribution with a high mode, to simulate how a human might transition between random actions every few steps, but occasionally press and hold an action for an extended period, or rapidly transition between actions. This is modelled by the heavy tails of a cauchy distribution. New actions are also picked that aren't the same as previous actions, to model the fact that humans tend to pick new actions after a series of the same action.\n",
    "\n",
    "The action biases are as follows (after softmaxing these values):\n",
    "- 48.37% chance of picking a forwards action\n",
    "- 17.79% chance of picking a forwardsleft action\n",
    "- 17.79% chance of picking a forwardsright action\n",
    "- 3.97% chance of picking a left action\n",
    "- 3.97% chance of picking a right action\n",
    "- 2.41% chance of picking stationary action\n",
    "- 2.41% chance of picking a backwards left action\n",
    "- 2.41% chance of picking a backwards right action\n",
    "- 0.89% chance of picking a backwards action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cephalo_caudal_cauchy = {'step_length_distribution' : 'cauchy',\n",
    "                       'cauchy_mode' : 15,\n",
    "                       '0stationaryactionbias' : 1,\n",
    "                       '1rturnbias' : 1.5,\n",
    "                       '2lturnbias' : 1.5,\n",
    "                       '3forwardbias' : 4,\n",
    "                       '4forwardrbias' : 3,\n",
    "                       '5forwardlbias' : 3,\n",
    "                       '6backwardbias' : 0,\n",
    "                       '7backwardlbias' : 1,\n",
    "                       '8backwardrbias' : 1,\n",
    "                       'remove_prev_step': True,\n",
    "                       'aai_seed' : 2023,\n",
    "                       'agent_tag' : 'Random Action Agent cephalocaudal bias cauchy step length mode 15'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rerunAgentTable = False\n",
    "\n",
    "mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "if rerunAgentTable:\n",
    "    dropTable = \"DROP TABLE IF EXISTS randomactionagentinstanceresults, randomactionagentintrainstanceresults, randomactionagents;\"\n",
    "    mycursor.execute(dropTable)\n",
    "    \n",
    "    sql = \"CREATE TABLE `randomactionagents` (`agentid` INT AUTO_INCREMENT PRIMARY KEY, `agent_tag` VARCHAR(300), `aai_seed` INT, `step_length_distribution` VARCHAR(10), `max_step_length` INT, `norm_mu` FLOAT(8), `norm_sig` FLOAT(8), `beta_alpha` FLOAT(8), `beta_beta` FLOAT(8), cauchy_mode FLOAT(8), gamma_kappa FLOAT(8), gamma_theta FLOAT(8), weibull_alpha FLOAT(8), poisson_lambda FLOAT(8), 0stationaryactionbias FLOAT(8), 1rturnbias FLOAT(8), 2lturnbias FLOAT(8), 3forwardbias FLOAT(8), 4forwardrbias FLOAT(8), 5forwardlbias FLOAT(8), 6backwardbias FLOAT(8), 7backwardlbias FLOAT(8), 8backwardrbias FLOAT(8), prev_step_bias FLOAT(8), remove_prev_step BOOL, UNIQUE(agent_tag, aai_seed));\"\n",
    "    mycursor.execute(sql)\n",
    "\n",
    "mycursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_dict_list = [uniform_action_agent, cephalo_caudal_cauchy]\n",
    "\n",
    "seeds_to_run = [2023, 1997, 356, 1815, 3761] #5 seeds corresponding to eventful years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "for agent in agent_dict_list:\n",
    "    for seed in seeds_to_run:\n",
    "        agent['aai_seed'] = seed\n",
    "        agentToDB(mycursor, agent, table_name = \"randomactionagents\")\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "mycursor.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Inference And Store\n",
    "\n",
    "Need to iterate through the dictionaries and run inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "rebuildInstanceResultsTables = False\n",
    "\n",
    "if rebuildInstanceResultsTables:\n",
    "    print(\"Rebuilding results tables, dropping if they already exist.\")\n",
    "\n",
    "    dropInstanceResultsTables = \"DROP TABLE IF EXISTS randomactionagentinstanceresults, randomactionagentintrainstanceresults;\"\n",
    "    mycursor.execute(dropInstanceResultsTables)\n",
    "    \n",
    "    createInstanceTable = \"CREATE TABLE randomactionagentinstanceresults(instanceid INT NOT NULL, agentid INT NOT NULL, finalreward FLOAT(53), FOREIGN KEY (instanceid) REFERENCES instances(instanceid), FOREIGN KEY(agentid) REFERENCES randomactionagents(agentid), PRIMARY KEY (instanceid, agentid));\"\n",
    "    mycursor.execute(createInstanceTable)\n",
    "\n",
    "    createIntraInstanceTable = \"CREATE TABLE randomactionagentintrainstanceresults(instanceid INT NOT NULL, agentid INT NOT NULL, step INT NOT NULL, actiontaken INT NOT NULL, stepreward FLOAT(53), xvelocity FLOAT(32), yvelocity FLOAT(32), zvelocity FLOAT(32), xpos FLOAT(32), ypos FLOAT(32), zpos FLOAT(32), FOREIGN KEY (instanceid) REFERENCES instances(instanceid), FOREIGN KEY(agentid) REFERENCES randomactionagents(agentid), PRIMARY KEY(instanceid, agentid, step));\"\n",
    "    mycursor.execute(createIntraInstanceTable)\n",
    "\n",
    "    print(\"Tables: randomactionagentinstanceresults and randomactionagentintrainstanceresults have been successfully built.\")\n",
    "\n",
    "mycursor.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function to run the experiments. This takes an agent dictionary and first checks whether any results have been recorded for it. If not, then it proceeds with testing. It does testing in batches, generating a temporary yml file to run training on and storing the final episode reward, as well as the intra-instance results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runRandomActionAgentAndStore (cur, con, batch_size: int, agent_dict: dict, yaml_files, task_names, temp_folder_location, agent_inference = False, port_base = 6600, randomise_port = True, verbose = True):\n",
    "    \n",
    "    # first, check if this agent has been added to the DB already\n",
    "\n",
    "    agentid = selectID(cur, id_name = \"agentid\", table_name = \"randomactionagents\", WHERE_column = \"agent_tag\", WHERE_clause = agent_dict['agent_tag'], secondary_WHERE_column = \"aai_seed\", secondary_WHERE_clause = agent_dict['aai_seed'])\n",
    "    \n",
    "    try:\n",
    "        task_names, yaml_files = removePreviouslyRunInstances(cur = cur, yaml_files=yaml_files, task_names=task_names, agentid=agentid, agent_table = \"randomactionagents\", agent_instance_results_table = \"randomactionagentinstanceresults\")\n",
    "    except:\n",
    "        print(\"Running on all files.\")\n",
    "\n",
    "    # now proceed with testing\n",
    "    yaml_index = 0\n",
    "\n",
    "    if randomise_port:\n",
    "\n",
    "        port = port_base + yaml_index + random.randint( #create random base port.\n",
    "            0, 9000\n",
    "            )\n",
    "        \n",
    "    else:\n",
    "        port = port_base + yaml_index\n",
    "        \n",
    "    batch_counter = 0\n",
    "\n",
    "    #set seed\n",
    "    random.seed(agent_dict['aai_seed'])\n",
    "\n",
    "    if len(yaml_files) > 0:\n",
    "        for yaml_index in range(0, len(yaml_files), batch_size):\n",
    "\n",
    "            if (yaml_index + batch_size) > len(yaml_files) or batch_size > len(yaml_files):\n",
    "                upper_bound = len(yaml_files)\n",
    "            else:\n",
    "                upper_bound = ((yaml_index + batch_size))\n",
    "\n",
    "            if verbose:\n",
    "                print(f\"Running inferences on batch {batch_counter + 1} of {batch_size} files of total {len(yaml_files)}. {len(yaml_files) - (batch_size * (batch_counter + 1))} instances to go.\")\n",
    "\n",
    "            batch_files = yaml_files[yaml_index:upper_bound]\n",
    "\n",
    "            batch_file_names = task_names[yaml_index:upper_bound]\n",
    "\n",
    "            batch_temp_file_name = f\"TempConfig_{agent_dict['agent_tag']}_{agent_dict['aai_seed']}_{yaml_index}.yml\"\n",
    "\n",
    "            config_file_path = yaml_combinor(file_list = batch_files, temp_file_location=temp_folder_location, stored_file_name = batch_temp_file_name)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Opening AAI Environment.\")\n",
    "\n",
    "            temp_port = port + yaml_index # increment through ports to prevent calling the same socket.\n",
    "\n",
    "            aai_env = AnimalAIEnvironment( \n",
    "                inference=agent_inference, #Set true when watching the agent\n",
    "                seed = agent_dict['aai_seed'],\n",
    "                worker_id=agent_dict['aai_seed'],\n",
    "                file_name=env_path,\n",
    "                arenas_configurations=config_file_path,\n",
    "                base_port=temp_port,\n",
    "                useCamera=False,\n",
    "                resolution=4, #make resolution small to improve processing speed - random walkers don't need anything.\n",
    "                useRayCasts=False,\n",
    "                no_graphics=True\n",
    "            )\n",
    "\n",
    "            env = UnityToGymWrapper(aai_env, uint8_visual=False, allow_multiple_obs=True, flatten_branched=True)\n",
    "\n",
    "            obs = env.reset()  \n",
    "\n",
    "            agent = RandomActionAgent() # initialise agent class\n",
    "\n",
    "            for key, value in agent_dict.items(): #set the agent attributes to be whatever is in the dictionary, and default otherwsise.\n",
    "                if hasattr(agent, key):\n",
    "                    setattr(agent, key, value)\n",
    "\n",
    "            agent.action_biases = [agent_dict['0stationaryactionbias'], \n",
    "                                   agent_dict['1rturnbias'], \n",
    "                                   agent_dict['2lturnbias'], \n",
    "                                   agent_dict['3forwardbias'],\n",
    "                                   agent_dict['4forwardrbias'],\n",
    "                                   agent_dict['5forwardlbias'],\n",
    "                                   agent_dict['6backwardbias'],\n",
    "                                   agent_dict['7backwardlbias'],\n",
    "                                   agent_dict['8backwardrbias']]\n",
    "\n",
    "\n",
    "            for _instance in range(len(batch_files)): \n",
    "\n",
    "                #select a random action according to the biases. There is no previous step bias as there is no previous step at the start of an episode!\n",
    "                initialActionAgent = agent\n",
    "                initialActionAgent.prev_step_bias = 0 \n",
    "\n",
    "                previous_action = initialActionAgent.get_new_action(prev_step=0)\n",
    "\n",
    "                #get instance ID\n",
    "                instanceid = selectID(cur, id_name = \"instanceid\", table_name = \"instances\", WHERE_column = \"instancename\", WHERE_clause = batch_file_names[_instance])\n",
    "\n",
    "                #prepare to run instance\n",
    "                done = False\n",
    "\n",
    "                episodeReward = 0\n",
    "\n",
    "                step_counter = 0\n",
    "    \n",
    "                while not done:\n",
    "\n",
    "                    step_list = agent.get_num_steps(prev_step = previous_action)\n",
    "            \n",
    "                    for action in step_list:\n",
    "            \n",
    "                        obs, reward, done, info = env.step(int(action))\n",
    "\n",
    "                        env.render()\n",
    "             \n",
    "                        step_counter += 1\n",
    "\n",
    "                        episodeReward += reward\n",
    "\n",
    "                        previous_action = action\n",
    "\n",
    "                        try:\n",
    "                            intraInstanceQuery = intraInstanceQuery = f\"INSERT INTO randomactionagentintrainstanceresults(instanceid, agentid, step, actiontaken, stepreward, xvelocity, yvelocity, zvelocity, xpos, ypos, zpos) VALUES ({instanceid}, {agentid}, {step_counter}, {action}, {float(episodeReward)}, {obs[0][1]}, {obs[0][2]}, {obs[0][3]}, {obs[0][4]}, {obs[0][5]}, {obs[0][6]});\"\n",
    "                            cur.execute(intraInstanceQuery)\n",
    "                            #con.commit()\n",
    "         \n",
    "                        except:\n",
    "                            print(f\"There's something wrong with this step. Here's the query {intraInstanceQuery}\")\n",
    "                            pass\n",
    "\n",
    "                        if done:\n",
    "                            obs=env.reset()\n",
    "                            if verbose:\n",
    "                                print(f\"Episode Reward: {episodeReward}\")\n",
    "                            done = True #to be sure.\n",
    "                            break #break the for loop early\n",
    "                    \n",
    "                    \n",
    "                    if not done: # only keep going if episode not done yet.\n",
    "\n",
    "                        action = agent.get_new_action(prev_step = previous_action)\n",
    "\n",
    "                        obs, reward, done, info = env.step(int(action))\n",
    "\n",
    "                        step_counter += 1\n",
    "\n",
    "                        env.render()\n",
    "\n",
    "                        episodeReward += reward\n",
    "\n",
    "                        previous_action = action\n",
    "\n",
    "                        try:\n",
    "                            intraInstanceQuery = f\"INSERT INTO randomactionagentintrainstanceresults(instanceid, agentid, step, actiontaken, stepreward, xvelocity, yvelocity, zvelocity, xpos, ypos, zpos) VALUES ({instanceid}, {agentid}, {step_counter}, {action}, {float(episodeReward)}, {obs[0][1]}, {obs[0][2]}, {obs[0][3]}, {obs[0][4]}, {obs[0][5]}, {obs[0][6]});\"\n",
    "                            cur.execute(intraInstanceQuery)\n",
    "                            #con.commit()\n",
    "         \n",
    "                        except:\n",
    "                            print(f\"There's something wrong with this step. Here's the query {intraInstanceQuery}\")\n",
    "                            pass\n",
    "                        \n",
    "\n",
    "                        if done:\n",
    "                            if verbose:\n",
    "                                print(F\"Episode Reward: {episodeReward}\")\n",
    "                            obs=env.reset()\n",
    "                            done = True #to be sure.\n",
    "                            break\n",
    "\n",
    "                try:\n",
    "                    insertInstanceResults = f\"INSERT INTO randomactionagentinstanceresults(instanceid, agentid, finalreward) VALUES ({instanceid}, {agentid}, {episodeReward});\"\n",
    "                    cur.execute(insertInstanceResults)\n",
    "                    con.commit()\n",
    "                    if verbose:\n",
    "                        print(\"Pushing results to database.\")\n",
    "                except:\n",
    "                    print(\"It looks like this agent has already been tested on this instance.\")\n",
    "\n",
    "                    \n",
    "            env.close()\n",
    "\n",
    "            batch_counter += 1\n",
    "\n",
    "            os.remove(config_file_path)\n",
    "\n",
    "            if verbose:\n",
    "                print(\"Moving to next batch.\")\n",
    "\n",
    "    else:\n",
    "        if verbose:\n",
    "            print(\"This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\")\n",
    "\n",
    "       \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_agent_on_instance_wrapper(seed, agent, yaml_batch_size=1, port_base = 6600, randomise_port = True, verbose = True):\n",
    "    agent['aai_seed'] = seed\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Running {agent['agent_tag']} on seed {seed}.\")\n",
    "    \n",
    "    mycursor, connection = databaseConnector('databaseConnectionDetails.csv')\n",
    "\n",
    "    runRandomActionAgentAndStore(mycursor, connection, yaml_batch_size, agent_dict=agent, yaml_files=yaml_files, task_names=task_names, temp_folder_location=temp_folder_location, agent_inference=False, port_base = port_base, randomise_port = randomise_port, verbose = verbose)\n",
    "\n",
    "    mycursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9991999505436979\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 875 of 1 files of total 3326. 2451 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_874.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9991999505436979\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 876 of 1 files of total 3326. 2450 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_875.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9991999505436979\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 877 of 1 files of total 3326. 2449 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_876.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9991999505436979\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 878 of 1 files of total 3326. 2448 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_877.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9991999505436979\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 879 of 1 files of total 3326. 2447 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_878.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 3.1456001992337406\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 880 of 1 files of total 3326. 2446 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_879.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9991999505436979\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 881 of 1 files of total 3326. 2445 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_880.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9991999505436979\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 882 of 1 files of total 3326. 2444 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_881.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9991999505436979\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 883 of 1 files of total 3326. 2443 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_882.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 884 of 1 files of total 3326. 2442 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_883.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 885 of 1 files of total 3326. 2441 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_884.yml\n",
      "Opening AAI Environment.\n",
      "Sockets were occupied. Waiting 10 seconds and starting again.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 1768 instances that have already been run before.\n",
      "Running inferences on batch 1 of 1 files of total 2442. 2441 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_0.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kv301\\anaconda3\\envs\\animalaiv3\\lib\\site-packages\\gym\\spaces\\box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode Reward: -1.3971999411005527\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 2 of 1 files of total 2442. 2440 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_1.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 3 of 1 files of total 2442. 2439 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_2.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.4599999244092032\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 4 of 1 files of total 2442. 2438 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_3.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 5 of 1 files of total 2442. 2437 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_4.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.5431999866850674\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 6 of 1 files of total 2442. 2436 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_5.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 0.3831000216305256\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 7 of 1 files of total 2442. 2435 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_6.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.244400001480244\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 8 of 1 files of total 2442. 2434 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_7.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 9 of 1 files of total 2442. 2433 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_8.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.4819999897154048\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 10 of 1 files of total 2442. 2432 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_9.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 11 of 1 files of total 2442. 2431 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_10.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.0963999424129725\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 12 of 1 files of total 2442. 2430 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_11.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 13 of 1 files of total 2442. 2429 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_12.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.4599999244092032\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 14 of 1 files of total 2442. 2428 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_13.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 15 of 1 files of total 2442. 2427 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_14.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.0927999425912276\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 16 of 1 files of total 2442. 2426 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_15.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 1.370900048641488\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 17 of 1 files of total 2442. 2425 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_16.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 1.4400999788194895\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 18 of 1 files of total 2442. 2424 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_17.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 19 of 1 files of total 2442. 2423 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_18.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.1448000064119697\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 20 of 1 files of total 2442. 2422 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_19.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 21 of 1 files of total 2442. 2421 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_20.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.2264000023715198\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 22 of 1 files of total 2442. 2420 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_21.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 23 of 1 files of total 2442. 2419 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_22.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.2555999481119215\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 24 of 1 files of total 2442. 2418 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_23.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 25 of 1 files of total 2442. 2417 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_24.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.3407999438932166\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 26 of 1 files of total 2442. 2416 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_25.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 27 of 1 files of total 2442. 2415 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_26.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.11679994140286\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 28 of 1 files of total 2442. 2414 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_27.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 29 of 1 files of total 2442. 2413 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_28.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.4139999402686954\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 30 of 1 files of total 2442. 2412 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_29.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 31 of 1 files of total 2442. 2411 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_30.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.2899999992223457\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 32 of 1 files of total 2442. 2410 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_31.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 33 of 1 files of total 2442. 2409 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_32.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.1508000061148778\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 34 of 1 files of total 2442. 2408 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_33.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 0.6806000218493864\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 35 of 1 files of total 2442. 2407 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_34.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.1119999416405335\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 36 of 1 files of total 2442. 2406 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_35.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 37 of 1 files of total 2442. 2405 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_36.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.6715999803273007\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 38 of 1 files of total 2442. 2404 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_37.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 1.5982999209081754\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 39 of 1 files of total 2442. 2403 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_38.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.1659999389667064\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 40 of 1 files of total 2442. 2402 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_39.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 41 of 1 files of total 2442. 2401 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_40.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.1371999403927475\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 42 of 1 files of total 2442. 2400 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_41.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 43 of 1 files of total 2442. 2399 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_42.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.8239999727811664\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 44 of 1 files of total 2442. 2398 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_43.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 45 of 1 files of total 2442. 2397 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_44.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.2552000009454787\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 46 of 1 files of total 2442. 2396 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_45.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 2.055100070312619\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 47 of 1 files of total 2442. 2395 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_46.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.0783999433042482\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 48 of 1 files of total 2442. 2394 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_47.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 49 of 1 files of total 2442. 2393 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_48.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 50 of 1 files of total 2442. 2392 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_49.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 1.5708000861341134\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 51 of 1 files of total 2442. 2391 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_50.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.2843999466858804\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 52 of 1 files of total 2442. 2390 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_51.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 53 of 1 files of total 2442. 2389 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_52.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.0927999425912276\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 54 of 1 files of total 2442. 2388 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_53.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 55 of 1 files of total 2442. 2387 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_54.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.0231999460374936\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 56 of 1 files of total 2442. 2386 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_55.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 57 of 1 files of total 2442. 2385 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_56.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.5895999179920182\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 58 of 1 files of total 2442. 2384 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_57.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 1.434800106449984\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 59 of 1 files of total 2442. 2383 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_58.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 2.836999920546077\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 60 of 1 files of total 2442. 2382 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_59.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 2.4541999395005405\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 61 of 1 files of total 2442. 2381 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_60.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.5787999185267836\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 62 of 1 files of total 2442. 2380 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_61.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 63 of 1 files of total 2442. 2379 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_62.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 64 of 1 files of total 2442. 2378 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_63.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: 2.026200066320598\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 65 of 1 files of total 2442. 2377 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_64.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.2911999991629273\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 66 of 1 files of total 2442. 2376 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_65.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 67 of 1 files of total 2442. 2375 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_66.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.0560000108089298\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 68 of 1 files of total 2442. 2374 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_67.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 69 of 1 files of total 2442. 2373 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_68.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.5163999216165394\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 70 of 1 files of total 2442. 2372 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_69.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 71 of 1 files of total 2442. 2371 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_70.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.1695999387884513\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 72 of 1 files of total 2442. 2370 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_71.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.3256999662844464\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 73 of 1 files of total 2442. 2369 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_72.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.0572000107495114\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 74 of 1 files of total 2442. 2368 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_73.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -0.9995999505044892\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 75 of 1 files of total 2442. 2367 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_74.yml\n",
      "Opening AAI Environment.\n",
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n",
      "Episode Reward: -1.4023999272612855\n",
      "Pushing results to database.\n",
      "Moving to next batch.\n",
      "Running inferences on batch 76 of 1 files of total 2442. 2366 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_75.yml\n",
      "Opening AAI Environment.\n",
      "Sockets were occupied. Waiting 10 seconds and starting again.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 4210 instances that have already been run before.\n",
      "This agent has already been run and is in the database. Skipping so as not to waste time. If you suspect that the agent has not been fully evaluated on all tests, you may want to restart the instances for that agent.\n",
      "Connected to database: `opiaagets` at `localhost` with user `agenttester`.\n",
      "Dropping 1843 instances that have already been run before.\n",
      "Running inferences on batch 1 of 1 files of total 2367. 2366 instances to go.\n",
      "Yaml files combined. Saved to ../../..\\TempConfig_Random Action Agent no bias no correlation uniform step length max 20_1956_0.yml\n",
      "Opening AAI Environment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Connected to Unity environment with package version 2.1.0-exp.1 and communication version 1.5.0\n",
      "[INFO] Connected new brain: AnimalAI?team=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kv301\\anaconda3\\envs\\animalaiv3\\lib\\site-packages\\gym\\spaces\\box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "yaml_batch_size = 1 #problem with task ordering, so having to do batches of 1. Much slower...\n",
    "counter = 0\n",
    "#inf_loop = True\n",
    "verbose = False\n",
    "\n",
    "while counter <= (len(seeds_to_run) * len(agent_dict_list)):\n",
    "    try:\n",
    "        for seed in seeds_to_run:\n",
    "            for agent_dictionary in agent_dict_list:\n",
    "                if keyboard.is_pressed('q'):\n",
    "                    print(f\"Loop stopped by pressing 'q'.\")\n",
    "                    break\n",
    "                adhoc_port = (counter+10)*100\n",
    "                run_agent_on_instance_wrapper(seed, agent_dictionary, yaml_batch_size=yaml_batch_size, port_base = adhoc_port, randomise_port = False, verbose = verbose)\n",
    "                if verbose:\n",
    "                    print(\"Moving to next seed.\")\n",
    "                counter += 1\n",
    "            if counter > (len(seeds_to_run) * len(agent_dict_list)):\n",
    "                break\n",
    "            if verbose:\n",
    "                 print(\"Moving to next agent.\")\n",
    "    except:\n",
    "        print(\"Sockets were occupied. Waiting 10 seconds and starting again.\")\n",
    "        counter = 0\n",
    "        if keyboard.is_pressed('q'):\n",
    "                    print(f\"Loop stopped by pressing 'q'.\")\n",
    "                    break\n",
    "        time.sleep(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "animalaiv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
